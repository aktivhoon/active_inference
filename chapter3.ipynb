{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Active Inference: A Novel Foundation to Understand Behavior and Cognition\n",
    "\n",
    "In fields like optimal control, reinforcement learning, and economics, the optimization of behavior results from a value function of states, following Bellman’s equation (Sutton and Barto 1998).\n",
    "\n",
    "In contrast, in Active Inference, behavior is the result of inference and its optimization is <U>a function of beliefs</U>. The agent’s preference for a course of action becomes simply a belief about what it expects to do, and to encounter, in the future. This is an apparently strange move, if one has a background in reinforcement learning (where value and belief are separated) or Bayesian statistics (where belief does not entail any value). \n",
    "\n",
    "However, it is a powerful move, for at least three reasons:\n",
    "### 1. Self-Consistent Process Model: \n",
    "* It automatically entails a self-consistent process model of purposive (or teleological) behavior, which is akin to cybernetic formulations. \n",
    "    * If we endow an Active Inference agent with some prior preference, then it will act to realize such preferences—because this is the only course of action consistent with its prior belief that it will act to fulfill its expectations.\n",
    "### 2. Degree of Belief and Uncertainty:\n",
    "* Casting behavior as a functional of beliefs (probability distributions) automatically entails notions such as <U>*degree of belief*</U> and <U>*uncertainty*</U>.\n",
    "    * it offers more flexibility in modeling sequential dynamics and itinerant behaviors.\n",
    "### 3. Hamiltonian Principle of Least Action: \n",
    "* In this formulation, optimal behavior comes to follow a Hamiltonian principle of least Action in statistical physics.\n",
    "    * behavior is a function of beliefs: it also assumes that it becomes an energy function.\n",
    "    * Thus, the most likely course of action is the one that minimizes free energy, aligning with the idea that living organisms follow a path of least resistance until they reach a steady state.\n",
    "    \n",
    "\n",
    "## Hamiltonian Physics and Active Inference Analogies\n",
    "\n",
    "### 1. Advance in theoretical models:\n",
    "* Like Lagrangian and Hamiltonian formulations brought advances to Newton’s accounts of mechanics, Active Inference offers a similar leap for the behavioral and life sciences. This theory reformulates the neuronal and behavioral dynamics usually formulated in differential equations by specifying a quantity—free energy—from which these dynamics may be derived. \n",
    "\n",
    "### 2. Hamiltonian and Probability Measures:\n",
    "* The second connection between Hamiltonian physics and Active Inference comes from associating the conserved Hamiltonian with the energy of the system.\n",
    "    * *Energy* is interpreted as a measure of the improbability (cf. negative log probability) of any given configuration of a system. Conservation of energy and probability are thus seen as equivalent laws. \n",
    "    * As dissipative systems move to states of low energy or high probability, we can directly associate the energy or Hamiltonian with surprise. Thus, Active Inference is Hamiltonian physics applied to systems featuring a Markov blanket.\n",
    "\n",
    "### 3. Variational Calculus:\n",
    "* In both Hamiltonian physics and Active Inference, functions (paths or beliefs) must be optimized concerning functionals (Action or free energy). In physics, this leads to the Euler-Lagrange equations, whereas in Active Inference, it leads to variational inference procedures.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models, Policies, and Trajectories\n",
    "\n",
    "1. The scope of Active Inference is relevant to systems that have some separation from their environment, signified by the presence of a **Markov blanket**. The persistence of this blanket necessitates dynamics that minimize the surprise of sensory states on average, leading to the conclusion that behavior is dictated by a steady-state distribution that can be interpreted as a **generative model** of how (sensory) data are generated.\n",
    "\n",
    "2. Each generative model should correlate with various types of behavior. By specifying different generative models, different types of behavior can be accounted for, implicitly defining what the system would find surprising. Additionally, different kinds of generative models may correspond to adaptive or cognitive creatures of varying complexity levels. Simpler generative models offer a minimal form of cognition as they cannot entertain the possibility of alternative (counterfactual) trajectories, and only allow inference at a single timescale.\n",
    "\n",
    "3. In contrast, **hierarchical generative models** allow inference at multiple timescales. In such models, slower-changing dynamics are encoded at higher hierarchical levels (providing context), and faster-changing elements are represented at lower levels.\n",
    "    1. models need the capacity to model **alternative futures** and select among them. This requires a generative model with some temporal depth and an explicit representation of the consequences of actions.\n",
    "    2. These alternative futures, are called policies or plans. Plans are chosen based on the lowest expected free energy, a measure of surprise or improbability, providing a framework for characterizing systems like us."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cybernetic & Predictive Theories under Active Inference\n",
    "\n",
    "### 1. Active inference is in keeping with enactive theories of life and cognition\n",
    "* Formal framework explaining how living organisms manage to resist dispersion of their states by self-organizing a statistical structure (Markov Blanket) that affords reciprocal exchanges between organism and environment, while also separating the organism's states from external, environmental dynamcis\n",
    "\n",
    "### 2. Active inference is in keeping with cybernetic theories\n",
    "* *Telology*: beyhavior is internally regulated by a mechanism that continuously tests whether a goal is achieved, and if not, steers corrective actions.\n",
    "* Active inference agents use both perception and action to minimize the discrepancy between preferred and sensed states\n",
    "* The variational free energy is what should be minimized, which is under certain condition, corresponding to a *prediction error*.\n",
    "\n",
    "### 3. Active inference is in keeping with theories that describe control as a prospective process that rests on a model of the environment\n",
    "* Active inference assuems that agents use a generative model to construct predictions, guiding their perception and action to evaluate their future.\n",
    "* Active inference is also coherent with ideomotor theory (action atarts with an imaginative process, and it is a predictive representation that triggers actions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active inference, from the emergence of life to agency\n",
    "\n",
    "* Active inference draws a line between those that mimimize *variational free energy* and those that also mimize *expected free energy*.\n",
    "\n",
    "### 1. Organisims which minimize variational free energy\n",
    "* Equivalenty an agent that actively gathers evidence for its generative model (= *self-evidencing agent*)\n",
    "* Avoid dissipation, self-regulate, and survive by achieving set-points (homeostasis)\n",
    "* Can generate complex and diverse forms of behavior, can also have very high fitness levels\n",
    "* However, these creatures are also fundamentally limited due to heir generative model lacking temporal depth\n",
    "\n",
    "### 2. Organisms which minimize expected free energy\n",
    "* Generative model endowed with temporal depth opens the door to the miminization of expected free energy (or, in psychological terms, **planning**)\n",
    "* Minimizing expected free energy is equivalent to having implicit prior that one is a free energy mimimizing agent, but acts to minimize free energy in the future\n",
    "* When the prior enters the generative model, the adaptive system becomes able to form belief about how to act in the future and which trajectories to follow (= select among alternative futures, as opposed to simply selecting how to deal with the sensed present)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
